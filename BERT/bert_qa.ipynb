{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","#Set a specific GPU\n","\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"  # Set the GPU 0 to use"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":257048,"status":"ok","timestamp":1658295928501,"user":{"displayName":"시현SeeYn","userId":"03029863824838417005"},"user_tz":-540},"id":"yRmeaod8WFkB","outputId":"52b08e69-d86d-4f1d-88d2-f04be36e89c5"},"outputs":[],"source":["import torch\n","import transformers\n","\n","from transformers import BertTokenizer\n","from transformers import BertForQuestionAnswering\n","from transformers import get_cosine_with_hard_restarts_schedule_with_warmup\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from torch.optim import AdamW\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","import numpy as np\n","import random\n","import time\n","import datetime\n","import re\n","import pickle\n","from tqdm.notebook import tqdm"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path /data5/dep_conv/JLK_NLP/code_qa_2/model_code/wandb/ wasn't writable, using system temp directory.\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","wandb: WARNING Path /data5/dep_conv/JLK_NLP/code_qa_2/model_code/wandb/ wasn't writable, using system temp directory\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path /data5/dep_conv/JLK_NLP/code_qa_2/model_code/wandb/ wasn't writable, using system temp directory\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjun171\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.13.3 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.13.1"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/tmp/wandb/run-20220921_042535-1xjbgz7c</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/jun171/test_jlk_nlp_qa_n/runs/1xjbgz7c\" target=\"_blank\">upbeat-sponge-35</a></strong> to <a href=\"https://wandb.ai/jun171/test_jlk_nlp_qa_n\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/jun171/test_jlk_nlp_qa_n/runs/1xjbgz7c?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7f3fadda3670>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import wandb\n","\n","wandb.init(project='test_jlk_nlp_qa_n')"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Device: cuda\n","Current cuda device: 0\n","Count of using GPUs: 1\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","print('Device:', device)\n","print('Current cuda device:', torch.cuda.current_device())\n","print('Count of using GPUs:', torch.cuda.device_count())"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":909,"status":"ok","timestamp":1658295942703,"user":{"displayName":"시현SeeYn","userId":"03029863824838417005"},"user_tz":-540},"id":"Ail6M6JkrUPL"},"outputs":[],"source":["main_loc = '../'\n","\n","with open(main_loc+'data/encoded_data_nl_s_fin.pkl','rb') as f:\n","    inputs_o, starts_o, ends_o, len_qs_o, masks_o = pickle.load(f)\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# inputs_o, _, starts_o, _, ends_o, _, masks_o, _ = \\\n","#     train_test_split(inputs_o, starts_o, ends_o, masks_o, random_state=1, test_size=0.98)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# with open(main_loc+'data/encoded_data_nl_small.pkl','wb') as f:\n","#     pickle.dump([inputs_o, starts_o, ends_o, masks_o],f)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1658295942704,"user":{"displayName":"시현SeeYn","userId":"03029863824838417005"},"user_tz":-540},"id":"vJzALRTKsA1a"},"outputs":[],"source":["train_inputs, test_inputs, train_starts, test_starts, train_ends, test_ends, train_masks, test_masks = \\\n","    train_test_split(inputs_o, starts_o, ends_o, masks_o, random_state=1, test_size=0.3)\n","    \n","train_inputs, validation_inputs, train_starts, validation_starts, train_ends, validation_ends, train_masks,validation_masks = \\\n","    train_test_split(train_inputs, train_starts, train_ends, train_masks, random_state=0, test_size=0.1)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1658295942705,"user":{"displayName":"시현SeeYn","userId":"03029863824838417005"},"user_tz":-540},"id":"Ewy8TmBwVvuY"},"outputs":[],"source":["root_address = main_loc+'model/'"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["e2b2f42e6682455793dfcddc195f9b4d","19b64cf912904913926db5703f15a094","4beee8c3e40d434e811e5b71ce8775c3","3acbf5e6b6e94f4bbdb482a57b5c5fbc","b4674f65216f46d5a13a1c3f18665615","e11c4e53794c415db83962402bfe3d26","b85a68fb1ebc4afc877518016e3f14d1","e8362a076b914bbf8c5fa67444695de4","512f445c46a344b6b34f885850a57e15","e9f3d81468f44fdab3d36e532e09024f","6c52704117064da18262cb0b436f20c1","b8e52e295a934886b47306d0770cbdb1","a546586deb5e487bb8cc41cfe8df4cf0","03bb75d5928241b4ba5dec3abf38eb93","7d068c6f19f349d7b0b0b95e475de25a","4983ef85e2364208a7682269d82b8056","c22e2099534e4932a08fab56787e4fa2","0fae54ca26c649c68c7e19b4ffd1ce22","d3d23e0af9144a13b40915fc98f776d7","60248bc7371f4190a3b7df24ff6f46c4","12676729e17e4d04bed918d50fcc2b9c","470d043f4226468b89730a93a89dacbd","df263dcc4493425a873ae380eb6bf06f","12b4ab9c43df45e895e08f85f92b8a4d","fdc0451db44d4c7980c267b067603272","7be061e6bd2f4ebb94e15f930aa5e94c","66462a6a595147caa04774934e2afe7d","07e11ad46051405d8ac4e5f7dc9efa8c","496bbaa0db424fc69ecb55b858058354","1aa7a45b98b9473197477e53032e1e0f","7d29d4c1fbea4d6889a3279ae4eabc9b","35eeafdf22264e118484a697cedae60b","c2c63d2b9e554283ae54c112ee848628"]},"executionInfo":{"elapsed":2753,"status":"ok","timestamp":1658295945452,"user":{"displayName":"시현SeeYn","userId":"03029863824838417005"},"user_tz":-540},"id":"Lc1yfspM4jqh","outputId":"ead7b720-7b66-4307-d04c-488ba57eee7e"},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# i = 0\n","# print(tokenizer.decode(inputs_o[i][starts_o[i]:ends_o[i]+1]))\n","# print(tokenizer.decode(inputs_o[i][len_qs_o[i][0]:len_qs_o[i][1]]))"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":1780,"status":"ok","timestamp":1658295994513,"user":{"displayName":"시현SeeYn","userId":"03029863824838417005"},"user_tz":-540},"id":"nUuUiy0WgLT0"},"outputs":[],"source":["train_inputs = torch.tensor(train_inputs)\n","train_starts = torch.tensor(train_starts)\n","train_ends = torch.tensor(train_ends)\n","train_masks = torch.tensor(train_masks)\n","\n","validation_inputs = torch.tensor(validation_inputs)\n","validation_starts = torch.tensor(validation_starts)\n","validation_ends = torch.tensor(validation_ends)\n","validation_masks = torch.tensor(validation_masks)\n","\n","test_inputs = torch.tensor(test_inputs)\n","test_starts = torch.tensor(test_starts)\n","test_ends = torch.tensor(test_ends)\n","test_masks = torch.tensor(test_masks)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1658295994513,"user":{"displayName":"시현SeeYn","userId":"03029863824838417005"},"user_tz":-540},"id":"Jyeum3tsgMzq"},"outputs":[],"source":["BATCH_SIZE = 24 #24\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_starts, train_ends)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_starts, validation_ends)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=BATCH_SIZE)\n","\n","test_data = TensorDataset(test_inputs, test_masks, test_starts, test_ends)\n","test_sampler = RandomSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1658295994514,"user":{"displayName":"시현SeeYn","userId":"03029863824838417005"},"user_tz":-540},"id":"OHDmPzFtgUsi"},"outputs":[],"source":["# model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n","\n","# model.to(device.type)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19234,"status":"ok","timestamp":1658296013727,"user":{"displayName":"시현SeeYn","userId":"03029863824838417005"},"user_tz":-540},"id":"WkiHMUY1ba7X","outputId":"882a7423-0459-44e2-e145-30bc32003b1f"},"outputs":[{"data":{"text/plain":["BertForQuestionAnswering(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n","      (position_embeddings): Embedding(512, 1024)\n","      (token_type_embeddings): Embedding(2, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (12): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (13): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (14): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (15): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (16): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (17): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (18): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (19): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (20): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (21): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (22): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (23): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",")"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["model = torch.load(root_address+'model_max_acc.pt')\n","\n","model.to(device.type)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1658296013727,"user":{"displayName":"시현SeeYn","userId":"03029863824838417005"},"user_tz":-540},"id":"grfJ8xnDgs4C","outputId":"3027c24f-66d5-4392-9a1a-6ed2308c7577"},"outputs":[],"source":["optimizer = AdamW(model.parameters(),\n","                  lr =1e-5, #3e-5\n","                  eps = 1e-12\n","                )\n","\n","epochs = 100\n","\n","\n","total_steps = len(train_dataloader) * epochs\n","\n","\n","scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps,\n","                                            num_cycles=20\n","                                            )"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1658296013728,"user":{"displayName":"시현SeeYn","userId":"03029863824838417005"},"user_tz":-540},"id":"fTEbUQ9EguXv"},"outputs":[],"source":["def cal_dis(f,id):\n","    rst = 0\n","    \n","    if abs(f-id)<5:\n","        rst+=1/((abs(f-id)+1)**2)\n","    else:\n","        pass\n","    \n","    return rst\n","\n","def calc_ans(flats,ids):\n","    rst = 0\n","    \n","    for f,id in zip(flats,ids):\n","        rst+=cal_dis(f,id)\n","\n","    return rst\n","\n","# def calc_ans_bt(st,end,st_ids,end_ids):\n","#     rst = 0\n","    \n","#     for sf,ef,s_id,e_id in zip(st, end, st_ids, end_ids):\n","#         rst+= cal_dis(sf,s_id)*cal_dis(ef,e_id)\n","    \n","#     return rst\n","\n","def is_same_text(sf,ef,s_id,e_id,input_id):\n","    re_t = tokenizer.decode(input_id[s_id:e_id+1]).strip()\n","    ex_t = tokenizer.decode(input_id[sf:ef+1]).strip()\n","    if re_t == ex_t:    \n","        return True\n","    else:\n","        return False\n","\n","def calc_ans_bt(st,end,st_ids,end_ids,input_ids):\n","    rst = 0\n","    \n","    for sf,ef,s_id,e_id,input_id in zip(st, end, st_ids, end_ids,input_ids):\n","        if is_same_text(sf,ef,s_id,e_id,input_id):\n","            rst+=1\n","\n","    return rst\n","\n","def print_expect_val(s_e,e_e,s_i,e_i,input_id):\n","    re_t = tokenizer.decode(input_id[s_i:e_i+1])\n","    print(f'Real text: {re_t}')\n","    if s_e<=e_e:\n","        ex_t = tokenizer.decode(input_id[s_e:e_e+1])\n","        print(f'Expect text: {ex_t}')\n","    else:\n","        print('No Expect text')\n","    print()\n","\n","# def flatten_proper_ans_set(st_s,end_s,n):\n","#     st_set = []\n","#     end_set = []\n","#     for st_p, end_p in zip(st_s,end_s):\n","#         st = st_p[-n:][0]\n","#         end = end_p[-n:][0]\n","#         st_set.append(st)\n","#         end_set.append(end)\n","    \n","#     return st_set,end_set\n","\n","\n","def flat_accuracy(st_ps,end_ps,st_ids,end_ids,input_ids, pr_t = False,k_n = 3):\n","    # st_flats = np.argsort(st_ps,kth = -k_n, axis=1)\n","    # end_flats = np.argsort(end_ps,kth = -k_n, axis=1)\n","    \n","    st_flat = np.argmax(st_ps, axis=1).flatten()\n","    end_flat = np.argmax(end_ps, axis=1).flatten()\n","    \n","    # st_acc = np.sum(st_flat == st_ids) / len(st_ids)\n","    # end_acc = np.sum(end_flat == end_ids) / len(end_ids)    \n","    # acc = np.sum((st_flat == st_ids) * (end_flat==end_ids)) / len(st_ids)   \n","    \n","    if pr_t: #check expected values\n","        for s_e,e_e,s_i,e_i,input_id in zip(st_flat,end_flat,st_ids,end_ids,input_ids):      \n","            if is_same_text(s_e,e_e,s_i,e_i,input_id)==False:\n","                print(f'Expect: {s_e},{e_e}. Real: {s_i},{e_i}')\n","                print_expect_val(s_e,e_e,s_i,e_i,input_id)\n","            \n","    \n","    st_acc = calc_ans(st_flat, st_ids) / len(st_ids)\n","    end_acc = calc_ans(end_flat, end_ids) / len(end_ids)\n","    \n","    acc = calc_ans_bt(st_flat,end_flat,st_ids,end_ids,input_ids) / len(st_ids)\n","\n","    return st_acc,end_acc,acc\n","\n","def format_time(elapsed):\n","\n","    elapsed_rounded = int(round((elapsed)))\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"eWHAyvvJgw-S","outputId":"0f7cbac3-da2d-4d60-a785-86468ee5fc78"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training...\n","======== Epoch 1 / 100 ========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"63b21d5e8be74a709db90def14ed3ce1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5641 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  Batch   500  of  5,641.    Elapsed: 0:14:11.\n","  Average loss =  0.7725441969037056\n","  Last learning rate: 9.99e-06\n","  Batch 1,000  of  5,641.    Elapsed: 0:28:18.\n","  Average loss =  0.7500127480626106\n","  Last learning rate: 9.97e-06\n","  Batch 1,500  of  5,641.    Elapsed: 0:42:26.\n","  Average loss =  0.7436734752058983\n","  Last learning rate: 9.93e-06\n","  Batch 2,000  of  5,641.    Elapsed: 0:56:34.\n","  Average loss =  0.7672943090200424\n","  Last learning rate: 9.88e-06\n","  Batch 2,500  of  5,641.    Elapsed: 1:10:43.\n","  Average loss =  0.7592478284835815\n","  Last learning rate: 9.81e-06\n","  Batch 3,000  of  5,641.    Elapsed: 1:24:52.\n","  Average loss =  0.7728655940592289\n","  Last learning rate: 9.72e-06\n","model_sv_0_on has been saved\n","  Batch 3,500  of  5,641.    Elapsed: 1:39:57.\n","  Average loss =  0.7638937972187996\n","  Last learning rate: 9.62e-06\n","  Batch 4,000  of  5,641.    Elapsed: 1:54:07.\n","  Average loss =  0.7839522058963776\n","  Last learning rate: 9.51e-06\n","  Batch 4,500  of  5,641.    Elapsed: 2:08:18.\n","  Average loss =  0.7642211804091931\n","  Last learning rate: 9.38e-06\n","  Batch 5,000  of  5,641.    Elapsed: 2:22:27.\n","  Average loss =  0.7729588754177094\n","  Last learning rate: 9.24e-06\n","  Batch 5,500  of  5,641.    Elapsed: 2:36:36.\n","  Average loss =  0.7819820702075958\n","  Last learning rate: 9.09e-06\n","\n","  Average training loss: 0.7668873667664148\n","  Training epoch took: 2:40:34\n","  Last learning rate: 9.05e-06\n","\n","Running Validation...\n","model_sv_0 has been saved\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"295eda693fa84045a4d46ca69a30d6b5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/627 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  st_token Accuracy: 0.60\n","  end_token Accuracy: 0.60\n","  all Accuracy: 0.58\n","  Validation took: 0:06:22\n","\n","Accuracy_nonzero: 0.58 is higher than previous maximum accuracy: 0.00\n","New model_max_acc has been saved\n","\n","Training...\n","======== Epoch 2 / 100 ========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dbc159f172b34cc3a6a6a53d3178c451","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5641 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  Batch   500  of  5,641.    Elapsed: 0:14:10.\n","  Average loss =  0.7375637495517731\n","  Last learning rate: 8.88e-06\n","  Batch 1,000  of  5,641.    Elapsed: 0:28:20.\n","  Average loss =  0.7362869591116905\n","  Last learning rate: 8.69e-06\n","  Batch 1,500  of  5,641.    Elapsed: 0:42:29.\n","  Average loss =  0.7469235206246376\n","  Last learning rate: 8.5e-06\n","  Batch 2,000  of  5,641.    Elapsed: 0:56:38.\n","  Average loss =  0.7400409332066774\n","  Last learning rate: 8.3e-06\n","  Batch 2,500  of  5,641.    Elapsed: 1:10:46.\n","  Average loss =  0.7533619495034218\n","  Last learning rate: 8.08e-06\n","  Batch 3,000  of  5,641.    Elapsed: 1:24:56.\n","  Average loss =  0.7474973101317882\n","  Last learning rate: 7.86e-06\n","model_sv_1_on has been saved\n","  Batch 3,500  of  5,641.    Elapsed: 1:39:18.\n","  Average loss =  0.7640580903887749\n","  Last learning rate: 7.62e-06\n","  Batch 4,000  of  5,641.    Elapsed: 1:53:29.\n","  Average loss =  0.7548687813282013\n","  Last learning rate: 7.38e-06\n","  Batch 4,500  of  5,641.    Elapsed: 2:07:39.\n","  Average loss =  0.7495323522686959\n","  Last learning rate: 7.14e-06\n","  Batch 5,000  of  5,641.    Elapsed: 2:21:48.\n","  Average loss =  0.768408652216196\n","  Last learning rate: 6.88e-06\n","  Batch 5,500  of  5,641.    Elapsed: 2:35:57.\n","  Average loss =  0.7735961624383927\n","  Last learning rate: 6.62e-06\n","\n","  Average training loss: 0.7531497888577426\n","  Training epoch took: 2:39:56\n","  Last learning rate: 6.55e-06\n","\n","Running Validation...\n","model_sv_1 has been saved\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"753a0455167a42e5b56a322131815759","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/627 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  st_token Accuracy: 0.60\n","  end_token Accuracy: 0.60\n","  all Accuracy: 0.57\n","  Validation took: 0:06:21\n","\n","Training...\n","======== Epoch 3 / 100 ========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"44dbd70ebc9a49068b79a549bb60e264","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5641 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  Batch   500  of  5,641.    Elapsed: 0:14:09.\n","  Average loss =  0.7346827134490013\n","  Last learning rate: 6.28e-06\n","  Batch 1,000  of  5,641.    Elapsed: 0:28:16.\n","  Average loss =  0.7254240836501121\n","  Last learning rate: 6.01e-06\n","  Batch 1,500  of  5,641.    Elapsed: 0:42:24.\n","  Average loss =  0.7338742761015892\n","  Last learning rate: 5.73e-06\n","  Batch 2,000  of  5,641.    Elapsed: 0:56:32.\n","  Average loss =  0.7534537640213966\n","  Last learning rate: 5.46e-06\n","  Batch 2,500  of  5,641.    Elapsed: 1:10:40.\n","  Average loss =  0.7402179727554321\n","  Last learning rate: 5.18e-06\n","  Batch 3,000  of  5,641.    Elapsed: 1:24:47.\n","  Average loss =  0.739889804661274\n","  Last learning rate: 4.9e-06\n","model_sv_2_on has been saved\n","  Batch 3,500  of  5,641.    Elapsed: 1:39:08.\n","  Average loss =  0.7453472906649112\n","  Last learning rate: 4.62e-06\n","  Batch 4,000  of  5,641.    Elapsed: 1:53:15.\n","  Average loss =  0.7562623009085655\n","  Last learning rate: 4.34e-06\n","  Batch 4,500  of  5,641.    Elapsed: 2:07:23.\n","  Average loss =  0.772107955634594\n","  Last learning rate: 4.07e-06\n","  Batch 5,000  of  5,641.    Elapsed: 2:21:31.\n","  Average loss =  0.7612923605442047\n","  Last learning rate: 3.8e-06\n","  Batch 5,500  of  5,641.    Elapsed: 2:35:39.\n","  Average loss =  0.7581379546523094\n","  Last learning rate: 3.53e-06\n","\n","  Average training loss: 0.7477457905609205\n","  Training epoch took: 2:39:37\n","  Last learning rate: 3.45e-06\n","\n","Running Validation...\n","model_sv_2 has been saved\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"812d83d05ae04f25a1b2604371f845c9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/627 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  st_token Accuracy: 0.59\n","  end_token Accuracy: 0.60\n","  all Accuracy: 0.58\n","  Validation took: 0:06:20\n","\n","Training...\n","======== Epoch 4 / 100 ========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed5811b4e52c4dfab6ec0bea388ffc02","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5641 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  Batch   500  of  5,641.    Elapsed: 0:14:08.\n","  Average loss =  0.7292264721393585\n","  Last learning rate: 3.19e-06\n","  Batch 1,000  of  5,641.    Elapsed: 0:28:16.\n","  Average loss =  0.7324612098932266\n","  Last learning rate: 2.94e-06\n","  Batch 1,500  of  5,641.    Elapsed: 0:42:24.\n","  Average loss =  0.7454685433506966\n","  Last learning rate: 2.69e-06\n","  Batch 2,000  of  5,641.    Elapsed: 0:56:32.\n","  Average loss =  0.7487250540852547\n","  Last learning rate: 2.44e-06\n","  Batch 2,500  of  5,641.    Elapsed: 1:10:40.\n","  Average loss =  0.7430379568338394\n","  Last learning rate: 2.21e-06\n","  Batch 3,000  of  5,641.    Elapsed: 1:24:47.\n","  Average loss =  0.7462230242490768\n","  Last learning rate: 1.98e-06\n","model_sv_3_on has been saved\n","  Batch 3,500  of  5,641.    Elapsed: 1:39:07.\n","  Average loss =  0.7583167610168458\n","  Last learning rate: 1.76e-06\n","  Batch 4,000  of  5,641.    Elapsed: 1:53:14.\n","  Average loss =  0.758340856730938\n","  Last learning rate: 1.56e-06\n","  Batch 4,500  of  5,641.    Elapsed: 2:07:20.\n","  Average loss =  0.7634074537754059\n","  Last learning rate: 1.36e-06\n","  Batch 5,000  of  5,641.    Elapsed: 2:21:25.\n","  Average loss =  0.7743634006381035\n","  Last learning rate: 1.17e-06\n","  Batch 5,500  of  5,641.    Elapsed: 2:35:31.\n","  Average loss =  0.7564804021120072\n","  Last learning rate: 1e-06\n","\n","  Average training loss: 0.7506269963523889\n","  Training epoch took: 2:39:29\n","  Last learning rate: 9.55e-07\n","\n","Running Validation...\n","model_sv_3 has been saved\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"27d7d457005f487fa510934ecce27c81","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/627 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  st_token Accuracy: 0.59\n","  end_token Accuracy: 0.60\n","  all Accuracy: 0.57\n","  Validation took: 0:06:20\n","\n","Training...\n","======== Epoch 5 / 100 ========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"60fbb02d9b3649ff9fe60f0ea79a1e48","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5641 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  Batch   500  of  5,641.    Elapsed: 0:14:07.\n","  Average loss =  0.7587836250066757\n","  Last learning rate: 7.98e-07\n","  Batch 1,000  of  5,641.    Elapsed: 0:28:14.\n","  Average loss =  0.7452387846112252\n","  Last learning rate: 6.53e-07\n","  Batch 1,500  of  5,641.    Elapsed: 0:42:20.\n","  Average loss =  0.7475883154273033\n","  Last learning rate: 5.22e-07\n","  Batch 2,000  of  5,641.    Elapsed: 0:56:24.\n","  Average loss =  0.7436265663504601\n","  Last learning rate: 4.06e-07\n","  Batch 2,500  of  5,641.    Elapsed: 1:10:26.\n","  Average loss =  0.745103566467762\n","  Last learning rate: 3.03e-07\n","  Batch 3,000  of  5,641.    Elapsed: 1:24:27.\n","  Average loss =  0.7500061175823212\n","  Last learning rate: 2.15e-07\n","model_sv_4_on has been saved\n","  Batch 3,500  of  5,641.    Elapsed: 1:38:51.\n","  Average loss =  0.7609812605977059\n","  Last learning rate: 1.42e-07\n","  Batch 4,000  of  5,641.    Elapsed: 1:52:54.\n","  Average loss =  0.7518181788921356\n","  Last learning rate: 8.33e-08\n","  Batch 4,500  of  5,641.    Elapsed: 2:06:55.\n","  Average loss =  0.7620311356186866\n","  Last learning rate: 4.03e-08\n","  Batch 5,000  of  5,641.    Elapsed: 2:20:57.\n","  Average loss =  0.7646437153816223\n","  Last learning rate: 1.27e-08\n","  Batch 5,500  of  5,641.    Elapsed: 2:34:59.\n","  Average loss =  0.7488446206450462\n","  Last learning rate: 6.17e-10\n","\n","  Average training loss: 0.7527659831423642\n","  Training epoch took: 2:38:56\n","  Last learning rate: 1e-05\n","\n","Running Validation...\n","model_sv_4 has been saved\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f2437cc01a3a42ce9bd26f5d66cf726b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/627 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  st_token Accuracy: 0.59\n","  end_token Accuracy: 0.59\n","  all Accuracy: 0.57\n","  Validation took: 0:06:19\n","\n","Training...\n","======== Epoch 6 / 100 ========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d63d34ba5c84b4cb1609bc8b28587f8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5641 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  Batch   500  of  5,641.    Elapsed: 0:14:03.\n","  Average loss =  0.6847846153378486\n","  Last learning rate: 9.99e-06\n","  Batch 1,000  of  5,641.    Elapsed: 0:28:05.\n","  Average loss =  0.7214593588709831\n","  Last learning rate: 9.97e-06\n","  Batch 1,500  of  5,641.    Elapsed: 0:42:07.\n","  Average loss =  0.7163117345273494\n","  Last learning rate: 9.93e-06\n","  Batch 2,000  of  5,641.    Elapsed: 0:56:09.\n","  Average loss =  0.7242327590584755\n","  Last learning rate: 9.88e-06\n","  Batch 2,500  of  5,641.    Elapsed: 1:10:10.\n","  Average loss =  0.7343321932554245\n","  Last learning rate: 9.81e-06\n","  Batch 3,000  of  5,641.    Elapsed: 1:24:10.\n","  Average loss =  0.7380776501297951\n","  Last learning rate: 9.72e-06\n","model_sv_5_on has been saved\n","  Batch 3,500  of  5,641.    Elapsed: 1:39:07.\n","  Average loss =  0.749914744079113\n","  Last learning rate: 9.62e-06\n","  Batch 4,000  of  5,641.    Elapsed: 1:53:09.\n","  Average loss =  0.7530464440584183\n","  Last learning rate: 9.51e-06\n","  Batch 4,500  of  5,641.    Elapsed: 2:07:11.\n","  Average loss =  0.7291125890761614\n","  Last learning rate: 9.38e-06\n","  Batch 5,000  of  5,641.    Elapsed: 2:21:13.\n","  Average loss =  0.7467806302905082\n","  Last learning rate: 9.24e-06\n","  Batch 5,500  of  5,641.    Elapsed: 2:35:14.\n","  Average loss =  0.7452970986366272\n","  Last learning rate: 9.09e-06\n","\n","  Average training loss: 0.7317115806850151\n","  Training epoch took: 2:39:11\n","  Last learning rate: 9.05e-06\n","\n","Running Validation...\n","model_sv_5 has been saved\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb7e0114bce24c42bfdeca17818d2f98","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/627 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  st_token Accuracy: 0.59\n","  end_token Accuracy: 0.59\n","  all Accuracy: 0.57\n","  Validation took: 0:06:19\n","\n","Running Test...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2484ec6a92fa489d82b9a64be4239951","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2687 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  st_token Accuracy: 0.60\n","  end_token Accuracy: 0.60\n","  all Accuracy: 0.58\n","  Test took: 0:26:13\n","\n","Training...\n","======== Epoch 7 / 100 ========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6cb802d1689b4f7abb6cac873427cc82","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5641 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  Batch   500  of  5,641.    Elapsed: 0:14:02.\n","  Average loss =  0.7721881268024444\n","  Last learning rate: 8.88e-06\n","  Batch 1,000  of  5,641.    Elapsed: 0:28:04.\n","  Average loss =  0.7780948332250118\n","  Last learning rate: 8.69e-06\n","  Batch 1,500  of  5,641.    Elapsed: 0:42:04.\n","  Average loss =  0.7809246983528138\n","  Last learning rate: 8.5e-06\n","  Batch 2,000  of  5,641.    Elapsed: 0:56:05.\n","  Average loss =  0.7689284391403198\n","  Last learning rate: 8.3e-06\n","  Batch 2,500  of  5,641.    Elapsed: 1:10:06.\n","  Average loss =  0.7842823544740677\n","  Last learning rate: 8.08e-06\n","  Batch 3,000  of  5,641.    Elapsed: 1:24:08.\n","  Average loss =  0.7900302202403545\n","  Last learning rate: 7.86e-06\n","model_sv_6_on has been saved\n","  Batch 3,500  of  5,641.    Elapsed: 1:38:22.\n","  Average loss =  0.7854645727872849\n","  Last learning rate: 7.62e-06\n","  Batch 4,000  of  5,641.    Elapsed: 1:52:25.\n","  Average loss =  0.7871225236654281\n","  Last learning rate: 7.38e-06\n","  Batch 4,500  of  5,641.    Elapsed: 2:06:27.\n","  Average loss =  0.8048384925723076\n","  Last learning rate: 7.14e-06\n","  Batch 5,000  of  5,641.    Elapsed: 2:20:28.\n","  Average loss =  0.7962645503878594\n","  Last learning rate: 6.88e-06\n","  Batch 5,500  of  5,641.    Elapsed: 2:34:30.\n","  Average loss =  0.7996028770208359\n","  Last learning rate: 6.62e-06\n","\n","  Average training loss: 0.7871608897697585\n","  Training epoch took: 2:38:27\n","  Last learning rate: 6.55e-06\n","\n","Running Validation...\n","model_sv_6 has been saved\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4e56bd3818ee4b68884452319879c0a8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/627 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  st_token Accuracy: 0.59\n","  end_token Accuracy: 0.60\n","  all Accuracy: 0.57\n","  Validation took: 0:06:19\n","\n","Training...\n","======== Epoch 8 / 100 ========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe2081a7cdea403096a802df149e0dc8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5641 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  Batch   500  of  5,641.    Elapsed: 0:14:02.\n","  Average loss =  0.7597169224619865\n","  Last learning rate: 6.28e-06\n","  Batch 1,000  of  5,641.    Elapsed: 0:28:04.\n","  Average loss =  0.7574184155464172\n","  Last learning rate: 6.01e-06\n","  Batch 1,500  of  5,641.    Elapsed: 0:42:06.\n","  Average loss =  0.7713719552159309\n","  Last learning rate: 5.73e-06\n","  Batch 2,000  of  5,641.    Elapsed: 0:56:07.\n","  Average loss =  0.7796014271378517\n","  Last learning rate: 5.46e-06\n","  Batch 2,500  of  5,641.    Elapsed: 1:10:10.\n","  Average loss =  0.7789711985588074\n","  Last learning rate: 5.18e-06\n","  Batch 3,000  of  5,641.    Elapsed: 1:24:11.\n","  Average loss =  0.7844129683971405\n","  Last learning rate: 4.9e-06\n","model_sv_7_on has been saved\n","  Batch 3,500  of  5,641.    Elapsed: 1:38:26.\n","  Average loss =  0.7686680991649628\n","  Last learning rate: 4.62e-06\n","  Batch 4,000  of  5,641.    Elapsed: 1:52:28.\n","  Average loss =  0.7581752816438675\n","  Last learning rate: 4.34e-06\n","  Batch 4,500  of  5,641.    Elapsed: 2:06:30.\n","  Average loss =  0.7853820073604584\n","  Last learning rate: 4.07e-06\n","  Batch 5,000  of  5,641.    Elapsed: 2:20:32.\n","  Average loss =  0.773737257450819\n","  Last learning rate: 3.8e-06\n","  Batch 5,500  of  5,641.    Elapsed: 2:34:34.\n","  Average loss =  0.7874933140873909\n","  Last learning rate: 3.53e-06\n","\n","  Average training loss: 0.7733549326499753\n","  Training epoch took: 2:38:31\n","  Last learning rate: 3.45e-06\n","\n","Running Validation...\n","model_sv_7 has been saved\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"83f9167e20044707badea7e2d2c802e0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/627 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  st_token Accuracy: 0.59\n","  end_token Accuracy: 0.59\n","  all Accuracy: 0.58\n","  Validation took: 0:06:20\n","\n","Training...\n","======== Epoch 9 / 100 ========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"08a7fe429cbb4e768e4f5f9e9ad47af4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5641 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  Batch   500  of  5,641.    Elapsed: 0:14:02.\n","  Average loss =  0.7400427107810974\n","  Last learning rate: 3.19e-06\n","  Batch 1,000  of  5,641.    Elapsed: 0:28:04.\n","  Average loss =  0.7594538595676422\n","  Last learning rate: 2.94e-06\n","  Batch 1,500  of  5,641.    Elapsed: 0:42:05.\n","  Average loss =  0.7553800438046455\n","  Last learning rate: 2.69e-06\n","  Batch 2,000  of  5,641.    Elapsed: 0:56:06.\n","  Average loss =  0.7566396964788437\n","  Last learning rate: 2.44e-06\n","  Batch 2,500  of  5,641.    Elapsed: 1:10:07.\n","  Average loss =  0.7484689727425575\n","  Last learning rate: 2.21e-06\n","  Batch 3,000  of  5,641.    Elapsed: 1:24:09.\n","  Average loss =  0.7619136061668396\n","  Last learning rate: 1.98e-06\n","model_sv_8_on has been saved\n","  Batch 3,500  of  5,641.    Elapsed: 1:38:24.\n","  Average loss =  0.7628930844664573\n","  Last learning rate: 1.76e-06\n","  Batch 4,000  of  5,641.    Elapsed: 1:52:27.\n","  Average loss =  0.7544398324489594\n","  Last learning rate: 1.56e-06\n","  Batch 4,500  of  5,641.    Elapsed: 2:06:29.\n","  Average loss =  0.7601663357019425\n","  Last learning rate: 1.36e-06\n","  Batch 5,000  of  5,641.    Elapsed: 2:20:31.\n","  Average loss =  0.7593331245779991\n","  Last learning rate: 1.17e-06\n","  Batch 5,500  of  5,641.    Elapsed: 2:34:33.\n","  Average loss =  0.7698025934696198\n","  Last learning rate: 1e-06\n","\n","  Average training loss: 0.7573134307689309\n","  Training epoch took: 2:38:31\n","  Last learning rate: 9.55e-07\n","\n","Running Validation...\n","model_sv_8 has been saved\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"88652ce346114d2a8512a2106de6209e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/627 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  st_token Accuracy: 0.59\n","  end_token Accuracy: 0.59\n","  all Accuracy: 0.58\n","  Validation took: 0:06:20\n","\n","Training...\n","======== Epoch 10 / 100 ========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77d75458b6f04cf09e4b7ad80f190549","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5641 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  Batch   500  of  5,641.    Elapsed: 0:14:03.\n","  Average loss =  0.7329920762777329\n","  Last learning rate: 7.98e-07\n","  Batch 1,000  of  5,641.    Elapsed: 0:28:05.\n","  Average loss =  0.7489016938209534\n","  Last learning rate: 6.53e-07\n","  Batch 1,500  of  5,641.    Elapsed: 0:42:08.\n","  Average loss =  0.7341307832002639\n","  Last learning rate: 5.22e-07\n","  Batch 2,000  of  5,641.    Elapsed: 0:56:17.\n","  Average loss =  0.7528952392935753\n","  Last learning rate: 4.06e-07\n","  Batch 2,500  of  5,641.    Elapsed: 1:10:25.\n","  Average loss =  0.7511899518072606\n","  Last learning rate: 3.03e-07\n","  Batch 3,000  of  5,641.    Elapsed: 1:24:33.\n","  Average loss =  0.7418562126755714\n","  Last learning rate: 2.15e-07\n","model_sv_9_on has been saved\n","  Batch 3,500  of  5,641.    Elapsed: 1:38:55.\n","  Average loss =  0.7434219599366189\n","  Last learning rate: 1.42e-07\n","  Batch 4,000  of  5,641.    Elapsed: 1:53:03.\n","  Average loss =  0.7644230405688286\n","  Last learning rate: 8.33e-08\n","  Batch 4,500  of  5,641.    Elapsed: 2:07:11.\n","  Average loss =  0.7444176729917527\n","  Last learning rate: 4.03e-08\n","  Batch 5,000  of  5,641.    Elapsed: 2:21:19.\n","  Average loss =  0.753153008878231\n","  Last learning rate: 1.27e-08\n","  Batch 5,500  of  5,641.    Elapsed: 2:35:27.\n","  Average loss =  0.7469425275623799\n","  Last learning rate: 6.17e-10\n","\n","  Average training loss: 0.7461611845828903\n","  Training epoch took: 2:39:25\n","  Last learning rate: 1e-05\n","\n","Running Validation...\n","model_sv_9 has been saved\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bdb80a223f6043c7b684f5be56fb7d5d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/627 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  st_token Accuracy: 0.59\n","  end_token Accuracy: 0.59\n","  all Accuracy: 0.57\n","  Validation took: 0:06:21\n","\n","Training...\n","======== Epoch 11 / 100 ========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3116d232c8aa43479efc5a7a78b04904","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5641 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  Batch   500  of  5,641.    Elapsed: 0:14:09.\n","  Average loss =  0.7660327640771866\n","  Last learning rate: 9.99e-06\n","  Batch 1,000  of  5,641.    Elapsed: 0:28:18.\n","  Average loss =  0.766852909386158\n","  Last learning rate: 9.97e-06\n","  Batch 1,500  of  5,641.    Elapsed: 0:42:27.\n","  Average loss =  0.768072758436203\n","  Last learning rate: 9.93e-06\n","  Batch 2,000  of  5,641.    Elapsed: 0:56:35.\n","  Average loss =  0.7881638633012772\n","  Last learning rate: 9.88e-06\n","  Batch 2,500  of  5,641.    Elapsed: 1:10:43.\n","  Average loss =  0.7729074205160141\n","  Last learning rate: 9.81e-06\n","  Batch 3,000  of  5,641.    Elapsed: 1:24:53.\n","  Average loss =  0.7842452843785286\n","  Last learning rate: 9.72e-06\n","model_sv_10_on has been saved\n","  Batch 3,500  of  5,641.    Elapsed: 1:39:26.\n","  Average loss =  0.7941295467615127\n","  Last learning rate: 9.62e-06\n","  Batch 4,000  of  5,641.    Elapsed: 1:53:35.\n","  Average loss =  0.7849389755725861\n","  Last learning rate: 9.51e-06\n","  Batch 4,500  of  5,641.    Elapsed: 2:07:44.\n","  Average loss =  0.7923840314149857\n","  Last learning rate: 9.38e-06\n","  Batch 5,000  of  5,641.    Elapsed: 2:21:52.\n","  Average loss =  0.7826322096884251\n","  Last learning rate: 9.24e-06\n","  Batch 5,500  of  5,641.    Elapsed: 2:36:00.\n","  Average loss =  0.8012990545034409\n","  Last learning rate: 9.09e-06\n","\n","  Average training loss: 0.7823041789028962\n","  Training epoch took: 2:39:59\n","  Last learning rate: 9.05e-06\n","\n","Running Validation...\n","model_sv_10 has been saved\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1145fbb58cfa4823b6c31610712ccfc7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/627 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  st_token Accuracy: 0.59\n","  end_token Accuracy: 0.59\n","  all Accuracy: 0.57\n","  Validation took: 0:06:33\n","\n","Running Test...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52acb4f4e24741078349db340bfbd06d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2687 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  st_token Accuracy: 0.59\n","  end_token Accuracy: 0.59\n","  all Accuracy: 0.57\n","  Test took: 0:26:22\n","\n","Training...\n","======== Epoch 12 / 100 ========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1eef1919d75d4d2b8e3626032182dff3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5641 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  Batch   500  of  5,641.    Elapsed: 0:14:08.\n","  Average loss =  0.7669549003243447\n","  Last learning rate: 8.88e-06\n","  Batch 1,000  of  5,641.    Elapsed: 0:28:16.\n","  Average loss =  0.7713912106752395\n","  Last learning rate: 8.69e-06\n","  Batch 1,500  of  5,641.    Elapsed: 0:42:23.\n","  Average loss =  0.7655382486581802\n","  Last learning rate: 8.5e-06\n","  Batch 2,000  of  5,641.    Elapsed: 0:56:33.\n","  Average loss =  0.7774509361386299\n","  Last learning rate: 8.3e-06\n","  Batch 2,500  of  5,641.    Elapsed: 1:10:42.\n","  Average loss =  0.7807841214537621\n","  Last learning rate: 8.08e-06\n","  Batch 3,000  of  5,641.    Elapsed: 1:24:50.\n","  Average loss =  0.7837914015054703\n","  Last learning rate: 7.86e-06\n","model_sv_11_on has been saved\n","  Batch 3,500  of  5,641.    Elapsed: 1:39:23.\n","  Average loss =  0.7776070953011512\n","  Last learning rate: 7.62e-06\n","  Batch 4,000  of  5,641.    Elapsed: 1:53:33.\n","  Average loss =  0.7726114713549614\n","  Last learning rate: 7.38e-06\n","  Batch 4,500  of  5,641.    Elapsed: 2:07:42.\n","  Average loss =  0.7862027835249901\n","  Last learning rate: 7.14e-06\n","  Batch 5,000  of  5,641.    Elapsed: 2:21:50.\n","  Average loss =  0.7811595460176468\n","  Last learning rate: 6.88e-06\n","  Batch 5,500  of  5,641.    Elapsed: 2:35:59.\n","  Average loss =  0.7945898312926293\n","  Last learning rate: 6.62e-06\n","\n","  Average training loss: 0.7774721286362778\n","  Training epoch took: 2:39:58\n","  Last learning rate: 6.55e-06\n","\n","Running Validation...\n","model_sv_11 has been saved\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"acdea4b361d64992b2d349bd5d57ad00","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/627 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  st_token Accuracy: 0.59\n","  end_token Accuracy: 0.59\n","  all Accuracy: 0.57\n","  Validation took: 0:07:14\n","\n","Training...\n","======== Epoch 13 / 100 ========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f59e1d2c7e894c6cb5db9c015e0b6fea","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5641 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  Batch   500  of  5,641.    Elapsed: 0:14:10.\n","  Average loss =  0.7601217958331108\n","  Last learning rate: 6.28e-06\n","  Batch 1,000  of  5,641.    Elapsed: 0:28:19.\n","  Average loss =  0.7627727025449276\n","  Last learning rate: 6.01e-06\n","  Batch 1,500  of  5,641.    Elapsed: 0:42:27.\n","  Average loss =  0.7451244171261787\n","  Last learning rate: 5.73e-06\n","  Batch 2,000  of  5,641.    Elapsed: 0:56:37.\n","  Average loss =  0.7567648948132992\n","  Last learning rate: 5.46e-06\n","  Batch 2,500  of  5,641.    Elapsed: 1:10:45.\n","  Average loss =  0.7704249260425567\n","  Last learning rate: 5.18e-06\n","  Batch 3,000  of  5,641.    Elapsed: 1:24:54.\n","  Average loss =  0.7675686801075935\n","  Last learning rate: 4.9e-06\n","model_sv_12_on has been saved\n","  Batch 3,500  of  5,641.    Elapsed: 1:39:17.\n","  Average loss =  0.756743400156498\n","  Last learning rate: 4.62e-06\n","  Batch 4,000  of  5,641.    Elapsed: 1:53:27.\n","  Average loss =  0.7640956081151963\n","  Last learning rate: 4.34e-06\n","  Batch 4,500  of  5,641.    Elapsed: 2:07:35.\n","  Average loss =  0.7682334042191505\n","  Last learning rate: 4.07e-06\n","  Batch 5,000  of  5,641.    Elapsed: 2:21:44.\n","  Average loss =  0.776964220404625\n","  Last learning rate: 3.8e-06\n","  Batch 5,500  of  5,641.    Elapsed: 2:35:54.\n","  Average loss =  0.7644694538712502\n","  Last learning rate: 3.53e-06\n","\n","  Average training loss: 0.7636938410180614\n","  Training epoch took: 2:39:52\n","  Last learning rate: 3.45e-06\n","\n","Running Validation...\n","model_sv_12 has been saved\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d3e8ef2155984ae7b734e81944151187","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/627 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  st_token Accuracy: 0.59\n","  end_token Accuracy: 0.59\n","  all Accuracy: 0.57\n","  Validation took: 0:06:21\n","\n","Training...\n","======== Epoch 14 / 100 ========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4b4f302982d43b4b46ea87249a8e786","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5641 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  Batch   500  of  5,641.    Elapsed: 0:14:09.\n","  Average loss =  0.7415168458223342\n","  Last learning rate: 3.19e-06\n","  Batch 1,000  of  5,641.    Elapsed: 0:28:18.\n","  Average loss =  0.7409661186933517\n","  Last learning rate: 2.94e-06\n","  Batch 1,500  of  5,641.    Elapsed: 0:42:27.\n","  Average loss =  0.7676552320122719\n","  Last learning rate: 2.69e-06\n","  Batch 2,000  of  5,641.    Elapsed: 0:56:36.\n","  Average loss =  0.7463097547888756\n","  Last learning rate: 2.44e-06\n","  Batch 2,500  of  5,641.    Elapsed: 1:10:45.\n","  Average loss =  0.7462800906300545\n","  Last learning rate: 2.21e-06\n","  Batch 3,000  of  5,641.    Elapsed: 1:24:53.\n","  Average loss =  0.7541936403512954\n","  Last learning rate: 1.98e-06\n","model_sv_13_on has been saved\n","  Batch 3,500  of  5,641.    Elapsed: 1:39:15.\n","  Average loss =  0.7416354954838753\n","  Last learning rate: 1.76e-06\n","  Batch 4,000  of  5,641.    Elapsed: 1:53:24.\n","  Average loss =  0.7496568002104759\n","  Last learning rate: 1.56e-06\n","  Batch 4,500  of  5,641.    Elapsed: 2:07:32.\n","  Average loss =  0.7505826153159142\n","  Last learning rate: 1.36e-06\n","  Batch 5,000  of  5,641.    Elapsed: 2:21:41.\n","  Average loss =  0.7482008947730064\n","  Last learning rate: 1.17e-06\n","  Batch 5,500  of  5,641.    Elapsed: 2:35:50.\n","  Average loss =  0.7515330176353454\n","  Last learning rate: 1e-06\n","\n","  Average training loss: 0.7490984463634653\n","  Training epoch took: 2:39:48\n","  Last learning rate: 9.55e-07\n","\n","Running Validation...\n","model_sv_13 has been saved\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"11d32de9f2bb42529b275730b6d80a7f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/627 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  st_token Accuracy: 0.59\n","  end_token Accuracy: 0.59\n","  all Accuracy: 0.57\n","  Validation took: 0:06:21\n","\n","Training...\n","======== Epoch 15 / 100 ========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a55b1410a0c344af8cce9dba53a48f47","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5641 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  Batch   500  of  5,641.    Elapsed: 0:14:09.\n","  Average loss =  0.7375157542824745\n","  Last learning rate: 7.98e-07\n","  Batch 1,000  of  5,641.    Elapsed: 0:28:18.\n","  Average loss =  0.7327121524810791\n","  Last learning rate: 6.53e-07\n","  Batch 1,500  of  5,641.    Elapsed: 0:42:26.\n","  Average loss =  0.7370313926339149\n","  Last learning rate: 5.22e-07\n","  Batch 2,000  of  5,641.    Elapsed: 0:56:35.\n","  Average loss =  0.7299596942663192\n","  Last learning rate: 4.06e-07\n","  Batch 2,500  of  5,641.    Elapsed: 1:10:43.\n","  Average loss =  0.7411395879387855\n","  Last learning rate: 3.03e-07\n","  Batch 3,000  of  5,641.    Elapsed: 1:24:48.\n","  Average loss =  0.7522118650078774\n","  Last learning rate: 2.15e-07\n","model_sv_14_on has been saved\n","  Batch 3,500  of  5,641.    Elapsed: 1:39:08.\n","  Average loss =  0.7354809569716454\n","  Last learning rate: 1.42e-07\n","  Batch 4,000  of  5,641.    Elapsed: 1:53:15.\n","  Average loss =  0.747198430120945\n","  Last learning rate: 8.33e-08\n","  Batch 4,500  of  5,641.    Elapsed: 2:07:21.\n","  Average loss =  0.7281898809075356\n","  Last learning rate: 4.03e-08\n","  Batch 5,000  of  5,641.    Elapsed: 2:21:28.\n","  Average loss =  0.7466445407569409\n","  Last learning rate: 1.27e-08\n","  Batch 5,500  of  5,641.    Elapsed: 2:35:34.\n","  Average loss =  0.7434405836462975\n","  Last learning rate: 6.17e-10\n","\n","  Average training loss: 0.739462758155077\n","  Training epoch took: 2:39:33\n","  Last learning rate: 1e-05\n","\n","Running Validation...\n","model_sv_14 has been saved\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"24b1445501b44f559753bc101511de4e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/627 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  st_token Accuracy: 0.59\n","  end_token Accuracy: 0.59\n","  all Accuracy: 0.57\n","  Validation took: 0:06:20\n","\n","Training...\n","======== Epoch 16 / 100 ========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3e24229cf41641869a05f692aebc1a88","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5641 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  Batch   500  of  5,641.    Elapsed: 0:14:07.\n","  Average loss =  0.7520213257074356\n","  Last learning rate: 9.99e-06\n","  Batch 1,000  of  5,641.    Elapsed: 0:28:14.\n","  Average loss =  0.756963781774044\n","  Last learning rate: 9.97e-06\n","  Batch 1,500  of  5,641.    Elapsed: 0:42:21.\n","  Average loss =  0.7660348912775516\n","  Last learning rate: 9.93e-06\n","  Batch 2,000  of  5,641.    Elapsed: 0:56:26.\n","  Average loss =  0.7679939370155334\n","  Last learning rate: 9.88e-06\n","  Batch 2,500  of  5,641.    Elapsed: 1:10:28.\n","  Average loss =  0.7729093528985977\n","  Last learning rate: 9.81e-06\n","  Batch 3,000  of  5,641.    Elapsed: 1:24:30.\n","  Average loss =  0.7751827995181084\n","  Last learning rate: 9.72e-06\n","model_sv_15_on has been saved\n","  Batch 3,500  of  5,641.    Elapsed: 1:38:44.\n","  Average loss =  0.7707837264537811\n","  Last learning rate: 9.62e-06\n","  Batch 4,000  of  5,641.    Elapsed: 1:52:46.\n","  Average loss =  0.7809451416134834\n","  Last learning rate: 9.51e-06\n","  Batch 4,500  of  5,641.    Elapsed: 2:06:47.\n","  Average loss =  0.7771344107985496\n","  Last learning rate: 9.38e-06\n","  Batch 5,000  of  5,641.    Elapsed: 2:20:49.\n","  Average loss =  0.7981060717105866\n","  Last learning rate: 9.24e-06\n","  Batch 5,500  of  5,641.    Elapsed: 2:34:51.\n","  Average loss =  0.7952724348902702\n","  Last learning rate: 9.09e-06\n","\n","  Average training loss: 0.7741817737450901\n","  Training epoch took: 2:38:48\n","  Last learning rate: 9.05e-06\n","\n","Running Validation...\n","model_sv_15 has been saved\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"16273bf5ac1445b09ba13f3861517c2d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/627 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  st_token Accuracy: 0.59\n","  end_token Accuracy: 0.59\n","  all Accuracy: 0.57\n","  Validation took: 0:06:20\n","\n","Running Test...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d1f01daa79a474aa34a274c2773be68","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2687 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  st_token Accuracy: 0.59\n","  end_token Accuracy: 0.59\n","  all Accuracy: 0.57\n","  Test took: 0:26:16\n","\n","Training...\n","======== Epoch 17 / 100 ========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ccf3b673b39451599fe068922620385","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5641 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  Batch   500  of  5,641.    Elapsed: 0:14:02.\n","  Average loss =  0.7666589644551277\n","  Last learning rate: 8.88e-06\n","  Batch 1,000  of  5,641.    Elapsed: 0:28:03.\n","  Average loss =  0.7645531268119812\n","  Last learning rate: 8.69e-06\n","  Batch 1,500  of  5,641.    Elapsed: 0:42:04.\n","  Average loss =  0.7616048728525638\n","  Last learning rate: 8.5e-06\n","  Batch 2,000  of  5,641.    Elapsed: 0:56:06.\n","  Average loss =  0.7698432173132896\n","  Last learning rate: 8.3e-06\n","  Batch 2,500  of  5,641.    Elapsed: 1:10:06.\n","  Average loss =  0.7719360879063606\n","  Last learning rate: 8.08e-06\n","  Batch 3,000  of  5,641.    Elapsed: 1:24:09.\n","  Average loss =  0.7625606741309165\n","  Last learning rate: 7.86e-06\n","model_sv_16_on has been saved\n","  Batch 3,500  of  5,641.    Elapsed: 1:38:23.\n","  Average loss =  0.7652093903422356\n","  Last learning rate: 7.62e-06\n","  Batch 4,000  of  5,641.    Elapsed: 1:52:26.\n","  Average loss =  0.7581919471621513\n","  Last learning rate: 7.38e-06\n","  Batch 4,500  of  5,641.    Elapsed: 2:06:28.\n","  Average loss =  0.7815096038579941\n","  Last learning rate: 7.14e-06\n","  Batch 5,000  of  5,641.    Elapsed: 2:20:30.\n","  Average loss =  0.7858460203409195\n","  Last learning rate: 6.88e-06\n","  Batch 5,500  of  5,641.    Elapsed: 2:34:32.\n","  Average loss =  0.7719164347052574\n","  Last learning rate: 6.62e-06\n","\n","  Average training loss: 0.7697166509687255\n","  Training epoch took: 2:38:30\n","  Last learning rate: 6.55e-06\n","\n","Running Validation...\n","model_sv_16 has been saved\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f3f32a68f18445e9b6bc9c9d9eb36e0f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/627 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  st_token Accuracy: 0.59\n","  end_token Accuracy: 0.59\n","  all Accuracy: 0.57\n","  Validation took: 0:06:32\n","\n","Training...\n","======== Epoch 18 / 100 ========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c8dda80570ab4cb68aad678948870cab","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5641 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["  Batch   500  of  5,641.    Elapsed: 0:14:03.\n","  Average loss =  0.7649317989945412\n","  Last learning rate: 6.28e-06\n","  Batch 1,000  of  5,641.    Elapsed: 0:28:05.\n","  Average loss =  0.7499041575491429\n","  Last learning rate: 6.01e-06\n","  Batch 1,500  of  5,641.    Elapsed: 0:42:08.\n","  Average loss =  0.7675535350143909\n","  Last learning rate: 5.73e-06\n","  Batch 2,000  of  5,641.    Elapsed: 0:56:10.\n","  Average loss =  0.7461438678205013\n","  Last learning rate: 5.46e-06\n","  Batch 2,500  of  5,641.    Elapsed: 1:10:12.\n","  Average loss =  0.7546912826895714\n","  Last learning rate: 5.18e-06\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/data5/dep_conv/JLK_NLP/code_qa_2/model_code/bert_test_qa_tag_nl.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223139322e3136382e302e33375f4a4c4b5f475055227d/data5/dep_conv/JLK_NLP/code_qa_2/model_code/bert_test_qa_tag_nl.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# print('loss', loss)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223139322e3136382e302e33375f4a4c4b5f475055227d/data5/dep_conv/JLK_NLP/code_qa_2/model_code/bert_test_qa_tag_nl.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223139322e3136382e302e33375f4a4c4b5f475055227d/data5/dep_conv/JLK_NLP/code_qa_2/model_code/bert_test_qa_tag_nl.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223139322e3136382e302e33375f4a4c4b5f475055227d/data5/dep_conv/JLK_NLP/code_qa_2/model_code/bert_test_qa_tag_nl.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), \u001b[39m1.0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223139322e3136382e302e33375f4a4c4b5f475055227d/data5/dep_conv/JLK_NLP/code_qa_2/model_code/bert_test_qa_tag_nl.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n","File \u001b[0;32m~/anaconda3/envs/JLK_NLP/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n","File \u001b[0;32m~/anaconda3/envs/JLK_NLP/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["seed_val = 0\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","model.zero_grad()\n","\n","max_acc = 0\n","\n","for epoch_i in range(0, epochs):\n","    print(f'Training...\\n======== Epoch {epoch_i + 1} / {epochs} ========')\n","    \n","    t0 = time.time()\n","    total_loss = 0\n","    prev_loss = 0\n","    prev_step = 0\n","    \n","    model.train()\n","    \n","    for step, batch in enumerate(tqdm(train_dataloader)):\n","\n","        if step % 500 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            step_loss = (total_loss-prev_loss) / (step-prev_step)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","            print(f'  Average loss =  {step_loss}')\n","            print(f\"  Last learning rate: {scheduler.get_last_lr()[0]:.3}\")\n","            \n","            wandb.log({\"step loss\": step_loss}, step=epoch_i*len(train_dataloader)+step)\n","            prev_loss = total_loss\n","            prev_step = step\n","                        \n","        if step % 3000 == 0 and not step == 0:\n","            torch.save(model,root_address+f'model_sv_{epoch_i}_on.pt')\n","            print(f'model_sv_{epoch_i}_on has been saved')\n","            \n","\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        b_input_ids, b_input_mask, b_starts, b_ends = batch\n","\n","        optimizer.zero_grad()\n","\n","        # Forward         \n","        outputs = model(b_input_ids, \n","                        attention_mask = b_input_mask,\n","                        start_positions = b_starts,\n","                        end_positions = b_ends)\n","        \n","        st_logits = outputs['start_logits']\n","        # print('st_log',st_logits)\n","        # print('st_log_max',max(st_logits[0]))\n","        end_logits = outputs['end_logits']\n","        # print('end_log',end_logits)\n","        \n","        loss = outputs[0]\n","        # print('loss', loss)\n","\n","        total_loss += loss.item()\n","\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        optimizer.step()\n","\n","        scheduler.step()\n","\n","\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","\n","    print(\"\")\n","    print(\"  Average training loss: {:}\".format(avg_train_loss))\n","    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n","    print(f\"  Last learning rate: {scheduler.get_last_lr()[0]:.3}\")\n","    print(\"\")        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    print(\"Running Validation...\")\n","\n","\n","    t0 = time.time()\n","\n","    torch.save(model,root_address+f'model_sv_{epoch_i}.pt')\n","    print(f'model_sv_{epoch_i} has been saved')\n","\n","    if epoch_i >=2:\n","        os.remove(root_address+f'model_sv_{epoch_i-2}.pt')\n","        os.remove(root_address+f'model_sv_{epoch_i-2}_on.pt')\n","    #Evaluation\n","    model.eval()\n","\n","    eval_loss, eval_accuracy1,eval_accuracy2,eval_accuracy3 = 0, 0, 0, 0\n","    nb_eval_steps = 0\n","\n","    for batch in tqdm(validation_dataloader):\n","\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","\n","        b_input_ids, b_input_mask, b_starts, b_ends = batch\n","\n","        with torch.no_grad():     \n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)\n","        \n","        st_logits = outputs['start_logits']\n","        end_logits = outputs['end_logits']\n","\n","        st_logits = st_logits.detach().cpu().numpy()\n","        end_logits = end_logits.detach().cpu().numpy()\n","        start_ids = b_starts.to('cpu').numpy()\n","        end_ids = b_ends.to('cpu').numpy()\n","        \n","        \n","        tmp_eval_accuracy1,tmp_eval_accuracy2,tmp_eval_accuracy3 = flat_accuracy(st_logits,end_logits, start_ids, end_ids,input_ids = b_input_ids)\n","        eval_accuracy1 += tmp_eval_accuracy1\n","        eval_accuracy2 += tmp_eval_accuracy2\n","        eval_accuracy3 += tmp_eval_accuracy3\n","\n","        nb_eval_steps += 1\n","        \n","    acc_all = eval_accuracy3/nb_eval_steps\n","\n","    print(\"  st_token Accuracy: {0:.2f}\".format(eval_accuracy1/nb_eval_steps))\n","    print(\"  end_token Accuracy: {0:.2f}\".format(eval_accuracy2/nb_eval_steps))\n","    print(\"  all Accuracy: {0:.2f}\".format(acc_all))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","    \n","    wandb.log({\"val_accuracy\": acc_all,\"loss\": avg_train_loss, \"learning_rate\": scheduler.get_last_lr()[0]}, step=epoch_i)\n","    \n","    if max_acc < acc_all:\n","        print(\"\")\n","        print(f\"Accuracy_nonzero: {acc_all:0.2f} is higher than previous maximum accuracy: {max_acc:0.2f}\")\n","        max_acc = acc_all\n","        torch.save(model,root_address+'model_max_acc.pt')\n","        print(f'New model_max_acc has been saved')    \n","    \n","    print(\"\")\n","\n","    # ========================================\n","    #                  Test\n","    # ========================================\n","    if epoch_i%5 ==0 and epoch_i !=0:    \n","        print(\"Running Test...\")\n","\n","        t0 = time.time()\n","            \n","        model.eval()\n","\n","        eval_loss, eval_accuracy1,eval_accuracy2,eval_accuracy3 = 0, 0, 0, 0\n","        nb_eval_steps = 0\n","\n","        for batch in tqdm(test_dataloader):\n","\n","            batch = tuple(t.to(device) for t in batch)\n","\n","            b_input_ids, b_input_mask, b_starts, b_ends = batch\n","\n","            with torch.no_grad():     \n","                outputs = model(b_input_ids, \n","                                token_type_ids=None, \n","                                attention_mask=b_input_mask)\n","            \n","            st_logits = outputs['start_logits']\n","            end_logits = outputs['end_logits']\n","\n","            st_logits = st_logits.detach().cpu().numpy()\n","            end_logits = end_logits.detach().cpu().numpy()\n","            start_ids = b_starts.to('cpu').numpy()\n","            end_ids = b_ends.to('cpu').numpy()\n","            \n","            \n","            tmp_eval_accuracy1,tmp_eval_accuracy2,tmp_eval_accuracy3 = flat_accuracy(st_logits,end_logits, start_ids, end_ids, input_ids=b_input_ids)\n","            eval_accuracy1 += tmp_eval_accuracy1\n","            eval_accuracy2 += tmp_eval_accuracy2\n","            eval_accuracy3 += tmp_eval_accuracy3\n","\n","            nb_eval_steps += 1\n","            \n","        acc_all = eval_accuracy3/nb_eval_steps\n","        \n","        wandb.log({\"test_accuracy\": acc_all}, step=epoch_i)\n","        \n","        print(\"  st_token Accuracy: {0:.2f}\".format(eval_accuracy1/nb_eval_steps))\n","        print(\"  end_token Accuracy: {0:.2f}\".format(eval_accuracy2/nb_eval_steps))\n","        print(\"  all Accuracy: {0:.2f}\".format(acc_all))\n","        print(\"  Test took: {:}\".format(format_time(time.time() - t0)))\n","\n","        print(\"\")\n","    \n","print(\"Training complete!\")\n","\n","torch.save(model,root_address+'model_fin.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LsZopqm9g5ot"},"outputs":[],"source":["# ========================================\n","#                  Test\n","# ========================================\n","print(\"Running Test...\")\n","\n","t0 = time.time()\n","    \n","model.eval()\n","\n","eval_loss, eval_accuracy1,eval_accuracy2,eval_accuracy3 = 0, 0, 0, 0\n","nb_eval_steps = 0\n","\n","for batch in tqdm(test_dataloader):\n","\n","    batch = tuple(t.to(device) for t in batch)\n","    \n","\n","    b_input_ids, b_input_mask, b_starts, b_ends = batch\n","\n","    with torch.no_grad():     \n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","    \n","    st_logits = outputs['start_logits']\n","    end_logits = outputs['end_logits']\n","\n","    st_logits = st_logits.detach().cpu().numpy()\n","    end_logits = end_logits.detach().cpu().numpy()\n","    start_ids = b_starts.to('cpu').numpy()\n","    end_ids = b_ends.to('cpu').numpy()\n","    \n","    \n","    tmp_eval_accuracy1,tmp_eval_accuracy2,tmp_eval_accuracy3 = flat_accuracy(st_logits,end_logits, start_ids, end_ids, input_ids=b_input_ids)\n","    eval_accuracy1 += tmp_eval_accuracy1\n","    eval_accuracy2 += tmp_eval_accuracy2\n","    eval_accuracy3 += tmp_eval_accuracy3\n","\n","    nb_eval_steps += 1\n","    \n","acc_all = eval_accuracy3/nb_eval_steps\n","wandb.log({\"End_test_accuracy\": acc_all})\n","\n","print(\"  st_token Accuracy: {0:.2f}\".format(eval_accuracy1/nb_eval_steps))\n","print(\"  end_token Accuracy: {0:.2f}\".format(eval_accuracy2/nb_eval_steps))\n","print(\"  all Accuracy: {0:.2f}\".format(acc_all))\n","print(\"  Test took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"bert_test_0711.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.12 ('JLK_NLP')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"345848687d23aa3dd821adb509f916c5b9e04f2482c626af90a89acdcc026ab8"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"03bb75d5928241b4ba5dec3abf38eb93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3d23e0af9144a13b40915fc98f776d7","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_60248bc7371f4190a3b7df24ff6f46c4","value":28}},"07e11ad46051405d8ac4e5f7dc9efa8c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fae54ca26c649c68c7e19b4ffd1ce22":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12676729e17e4d04bed918d50fcc2b9c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12b4ab9c43df45e895e08f85f92b8a4d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07e11ad46051405d8ac4e5f7dc9efa8c","placeholder":"​","style":"IPY_MODEL_496bbaa0db424fc69ecb55b858058354","value":"Downloading: 100%"}},"19b64cf912904913926db5703f15a094":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e11c4e53794c415db83962402bfe3d26","placeholder":"​","style":"IPY_MODEL_b85a68fb1ebc4afc877518016e3f14d1","value":"Downloading: 100%"}},"1aa7a45b98b9473197477e53032e1e0f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35eeafdf22264e118484a697cedae60b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3acbf5e6b6e94f4bbdb482a57b5c5fbc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9f3d81468f44fdab3d36e532e09024f","placeholder":"​","style":"IPY_MODEL_6c52704117064da18262cb0b436f20c1","value":" 226k/226k [00:00&lt;00:00, 626kB/s]"}},"470d043f4226468b89730a93a89dacbd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"496bbaa0db424fc69ecb55b858058354":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4983ef85e2364208a7682269d82b8056":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4beee8c3e40d434e811e5b71ce8775c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8362a076b914bbf8c5fa67444695de4","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_512f445c46a344b6b34f885850a57e15","value":231508}},"512f445c46a344b6b34f885850a57e15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"60248bc7371f4190a3b7df24ff6f46c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"66462a6a595147caa04774934e2afe7d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c52704117064da18262cb0b436f20c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7be061e6bd2f4ebb94e15f930aa5e94c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35eeafdf22264e118484a697cedae60b","placeholder":"​","style":"IPY_MODEL_c2c63d2b9e554283ae54c112ee848628","value":" 443/443 [00:00&lt;00:00, 16.1kB/s]"}},"7d068c6f19f349d7b0b0b95e475de25a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12676729e17e4d04bed918d50fcc2b9c","placeholder":"​","style":"IPY_MODEL_470d043f4226468b89730a93a89dacbd","value":" 28.0/28.0 [00:00&lt;00:00, 997B/s]"}},"7d29d4c1fbea4d6889a3279ae4eabc9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a546586deb5e487bb8cc41cfe8df4cf0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c22e2099534e4932a08fab56787e4fa2","placeholder":"​","style":"IPY_MODEL_0fae54ca26c649c68c7e19b4ffd1ce22","value":"Downloading: 100%"}},"b4674f65216f46d5a13a1c3f18665615":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b85a68fb1ebc4afc877518016e3f14d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8e52e295a934886b47306d0770cbdb1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a546586deb5e487bb8cc41cfe8df4cf0","IPY_MODEL_03bb75d5928241b4ba5dec3abf38eb93","IPY_MODEL_7d068c6f19f349d7b0b0b95e475de25a"],"layout":"IPY_MODEL_4983ef85e2364208a7682269d82b8056"}},"c22e2099534e4932a08fab56787e4fa2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2c63d2b9e554283ae54c112ee848628":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3d23e0af9144a13b40915fc98f776d7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df263dcc4493425a873ae380eb6bf06f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_12b4ab9c43df45e895e08f85f92b8a4d","IPY_MODEL_fdc0451db44d4c7980c267b067603272","IPY_MODEL_7be061e6bd2f4ebb94e15f930aa5e94c"],"layout":"IPY_MODEL_66462a6a595147caa04774934e2afe7d"}},"e11c4e53794c415db83962402bfe3d26":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2b2f42e6682455793dfcddc195f9b4d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_19b64cf912904913926db5703f15a094","IPY_MODEL_4beee8c3e40d434e811e5b71ce8775c3","IPY_MODEL_3acbf5e6b6e94f4bbdb482a57b5c5fbc"],"layout":"IPY_MODEL_b4674f65216f46d5a13a1c3f18665615"}},"e8362a076b914bbf8c5fa67444695de4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9f3d81468f44fdab3d36e532e09024f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdc0451db44d4c7980c267b067603272":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1aa7a45b98b9473197477e53032e1e0f","max":443,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d29d4c1fbea4d6889a3279ae4eabc9b","value":443}}}}},"nbformat":4,"nbformat_minor":0}
